# ConText-E: Multi-Modal Sentiment Analysis for Climate Change Discourse

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Accuracy](https://img.shields.io/badge/Accuracy-93.69%25-green.svg)]()

## ğŸ¯ Overview

ConText-E is an advanced sentiment analysis system that combines **semantic**, **emotional**, and **topical** features to achieve state-of-the-art performance on climate change discourse analysis. The system uses a novel three-phase pipeline that fine-tunes DeBERTa for semantic understanding, extracts emotional features using RoBERTa, and applies BERTopic for topic modeling, all integrated through a LightGBM meta-learner.

## ğŸš€ Key Features

- **Multi-Modal Architecture**: Combines semantic, emotional, and topical features
- **State-of-the-Art Performance**: 93.69% accuracy with 93.67% weighted F1-score
- **Robust Validation**: 5-fold stratified cross-validation
- **Large-Scale Dataset**: ~51K+ climate change tweets
- **Reproducible Research**: Complete pipeline with fixed random seeds
- **Production Ready**: End-to-end prediction system

## ğŸ“Š Performance Results

| Metric | Score |
|--------|-------|
| **Cross-Validation Accuracy** | **93.69%** |
| **Weighted F1-Score** | **93.67%** |
| **Individual Fold Accuracy** | 93.14% - 94.12% |
| **Dataset Size** | 51,419 tweets |
| **Feature Dimensions** | 902 |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Phase 1:      â”‚    â”‚   Phase 2:      â”‚    â”‚   Phase 3:      â”‚
â”‚   Feature       â”‚    â”‚   DeBERTa       â”‚    â”‚   Meta-Learner  â”‚
â”‚   Engineering   â”‚    â”‚   Fine-tuning   â”‚    â”‚   Training      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Emotional     â”‚    â”‚ â€¢ Semantic      â”‚    â”‚ â€¢ LightGBM      â”‚
â”‚   Features      â”‚    â”‚   Embeddings    â”‚    â”‚   Meta-Learner  â”‚
â”‚   (RoBERTa)     â”‚    â”‚   (DeBERTa)     â”‚    â”‚ â€¢ 5-Fold CV     â”‚
â”‚ â€¢ Topic         â”‚    â”‚ â€¢ Fine-tuned    â”‚    â”‚ â€¢ Feature       â”‚
â”‚   Features      â”‚    â”‚   Model         â”‚    â”‚   Fusion        â”‚
â”‚   (BERTopic)    â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- CUDA-compatible GPU (recommended)
- 8GB+ RAM

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/ConText-E_Project.git
cd ConText-E_Project
```

2. **Create virtual environment**
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

## ğŸš€ Quick Start

### 1. Feature Engineering
```bash
python src/01_feature_engineering.py
```
- Generates emotional features using RoBERTa
- Creates topic features using BERTopic
- Processes ~51K tweets (15-30 minutes)

### 2. DeBERTa Fine-tuning
```bash
python src/02_finetune_deberta.py
```
- Fine-tunes DeBERTa-v3-base on sentiment data
- Saves semantic core model (1.5-3 hours)

### 3. Meta-Learner Training
```bash
python src/03_train_meta_learner.py
```
- Trains LightGBM meta-learner with 5-fold CV
- Combines all feature modalities
- Achieves 93.69% accuracy

### 4. Make Predictions
```bash
python src/predict.py
```
- Interactive sentiment prediction
- Real-time analysis of user input

## ğŸ“ Project Structure

```
ConText-E_Project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ 01_feature_engineering.py    # Phase 1: Feature extraction
â”‚   â”œâ”€â”€ 02_finetune_deberta.py       # Phase 2: DeBERTa fine-tuning
â”‚   â”œâ”€â”€ 03_train_meta_learner.py     # Phase 3: Meta-learner training
â”‚   â””â”€â”€ predict.py                   # Prediction interface
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ twitter_sentiment_data.csv   # Raw dataset
â”‚   â””â”€â”€ enriched_data.csv            # Processed features
â”œâ”€â”€ saved_models/
â”‚   â”œâ”€â”€ bertopic_model/              # Topic modeling model
â”‚   â”œâ”€â”€ deberta_semantic_core/       # Fine-tuned DeBERTa
â”‚   â””â”€â”€ lgbm_meta_learner.pkl        # Meta-learner model
â”œâ”€â”€ results/                         # Training checkpoints
â””â”€â”€ requirements.txt                 # Dependencies
```

## ğŸ”¬ Research Contributions

### Novel Methodology
- **Multi-Modal Feature Fusion**: First to combine semantic, emotional, and topical features for sentiment analysis
- **Embedding-Based Meta-Learning**: Uses transformer embeddings as features rather than direct classification
- **Robust Validation**: Comprehensive cross-validation with proper stratification

### Technical Innovations
- **Semantic Features**: DeBERTa-v3-base embeddings (768 dimensions)
- **Emotional Features**: RoBERTa emotion classification (28 emotion categories)
- **Topical Features**: BERTopic clustering with one-hot encoding
- **Meta-Learning**: LightGBM ensemble for final prediction

## ğŸ“ˆ Experimental Results

### Cross-Validation Performance
| Fold | Accuracy | F1-Score |
|------|----------|----------|
| 1    | 93.14%   | 93.12%   |
| 2    | 94.03%   | 94.01%   |
| 3    | 93.52%   | 93.50%   |
| 4    | 94.12%   | 94.10%   |
| 5    | 93.64%   | 93.62%   |
| **Average** | **93.69%** | **93.67%** |

### Feature Analysis
- **Total Features**: 902 dimensions
- **Semantic Features**: 768 (DeBERTa embeddings)
- **Emotional Features**: 28 (emotion categories)
- **Topical Features**: 106 (topic clusters)

## ğŸ¯ Use Cases

- **Climate Change Research**: Analyze public sentiment on climate discourse
- **Social Media Monitoring**: Track sentiment trends on environmental topics
- **Policy Analysis**: Understand public opinion on climate policies
- **Academic Research**: Study sentiment patterns in climate communication

## ğŸ”§ Configuration

### Model Parameters
```python
# DeBERTa Fine-tuning
MODEL_NAME = "microsoft/deberta-v3-base"
LEARNING_RATE = 2e-5
BATCH_SIZE = 16
EPOCHS = 3

# LightGBM Meta-Learner
N_ESTIMATORS = 500
CV_FOLDS = 5
RANDOM_STATE = 42
```

### Hardware Requirements
- **GPU**: NVIDIA GPU with 8GB+ VRAM (recommended)
- **RAM**: 16GB+ system memory
- **Storage**: 10GB+ free space

## ğŸ“š Dependencies

### Core Libraries
- `transformers==4.41.2` - Hugging Face transformers
- `torch` - PyTorch deep learning framework
- `lightgbm` - Gradient boosting meta-learner
- `bertopic` - Topic modeling
- `scikit-learn` - Machine learning utilities

### Data Processing
- `pandas` - Data manipulation
- `numpy<2.0` - Numerical computing
- `datasets==2.19.0` - Dataset handling

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup
```bash
git clone https://github.com/yourusername/ConText-E_Project.git
cd ConText-E_Project
pip install -r requirements.txt
pip install -r requirements-dev.txt  # Development dependencies
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“– Citation

If you use this work in your research, please cite:

```bibtex
@article{context_e_2024,
  title={ConText-E: Multi-Modal Sentiment Analysis for Climate Change Discourse},
  author={Your Name},
  journal={Conference/Journal Name},
  year={2024},
  url={https://github.com/yourusername/ConText-E_Project}
}
```

## ğŸ™ Acknowledgments

- **Hugging Face** for transformer models and libraries
- **Microsoft** for DeBERTa-v3-base model
- **LightGBM** team for the gradient boosting framework
- **BERTopic** for topic modeling capabilities

## ğŸ“ Contact

- **Author**: Your Name
- **Email**: your.email@university.edu
- **GitHub**: [@yourusername](https://github.com/yourusername)
- **LinkedIn**: [Your Profile](https://linkedin.com/in/yourprofile)

## ğŸ”® Future Work

- [ ] Cross-domain evaluation on other sentiment datasets
- [ ] Ablation studies for feature importance
- [ ] Real-time streaming sentiment analysis
- [ ] Multi-language support
- [ ] Interpretability analysis

---

**â­ If you find this project useful, please give it a star!**
